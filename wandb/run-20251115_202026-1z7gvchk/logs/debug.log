2025-11-15 20:20:26,679 INFO    MainThread:92567 [wandb_setup.py:_flush():80] Current SDK version is 0.23.0
2025-11-15 20:20:26,679 INFO    MainThread:92567 [wandb_setup.py:_flush():80] Configure stats pid to 92567
2025-11-15 20:20:26,679 INFO    MainThread:92567 [wandb_setup.py:_flush():80] Loading settings from /Users/apple/.config/wandb/settings
2025-11-15 20:20:26,679 INFO    MainThread:92567 [wandb_setup.py:_flush():80] Loading settings from /Users/apple/Desktop/slm-lora-benchmark/wandb/settings
2025-11-15 20:20:26,679 INFO    MainThread:92567 [wandb_setup.py:_flush():80] Loading settings from environment variables
2025-11-15 20:20:26,679 INFO    MainThread:92567 [wandb_init.py:setup_run_log_directory():713] Logging user logs to /Users/apple/Desktop/slm-lora-benchmark/wandb/run-20251115_202026-1z7gvchk/logs/debug.log
2025-11-15 20:20:26,680 INFO    MainThread:92567 [wandb_init.py:setup_run_log_directory():714] Logging internal logs to /Users/apple/Desktop/slm-lora-benchmark/wandb/run-20251115_202026-1z7gvchk/logs/debug-internal.log
2025-11-15 20:20:26,680 INFO    MainThread:92567 [wandb_init.py:init():840] calling init triggers
2025-11-15 20:20:26,680 INFO    MainThread:92567 [wandb_init.py:init():845] wandb.init called with sweep_config: {}
config: {'model': {'name': 'gpt2', 'max_length': 512, 'use_cache': False}, 'lora': {'r': 8, 'lora_alpha': 16, 'lora_dropout': 0.05, 'target_modules': ['c_attn'], 'bias': 'none', 'task_type': 'CAUSAL_LM'}, 'training': {'num_epochs': 1, 'batch_size': 4, 'gradient_accumulation_steps': 4, 'learning_rate': '5e-5', 'warmup_steps': 100, 'weight_decay': 0.01, 'max_grad_norm': 1.0, 'seed': 42, 'log_every_steps': 10, 'save_every_steps': 200, 'output_dir': 'outputs/checkpoints'}, 'wandb': {'project': 'slm-lora-benchmark', 'entity': None, 'run_name': 'gpt2-wikitext2-lora-baseline'}, 'datasets': {'wikitext2': {'hf_name': 'wikitext', 'subset': 'wikitext-2-raw-v1', 'split': 'train', 'val_split': 'validation', 'text_field': 'text'}}, 'experiment': {'name': 'baseline_gpt2_wikitext2', 'use_dataset': 'wikitext2'}, 'include': ['model_config.yaml', 'lora_config.yaml', 'training_config.yaml', 'datasets.yaml'], '_wandb': {}}
2025-11-15 20:20:26,680 INFO    MainThread:92567 [wandb_init.py:init():888] starting backend
2025-11-15 20:20:27,180 INFO    MainThread:92567 [wandb_init.py:init():891] sending inform_init request
2025-11-15 20:20:27,252 INFO    MainThread:92567 [wandb_init.py:init():899] backend started and connected
2025-11-15 20:20:27,259 INFO    MainThread:92567 [wandb_init.py:init():969] updated telemetry
2025-11-15 20:20:27,314 INFO    MainThread:92567 [wandb_init.py:init():993] communicating run to backend with 90.0 second timeout
2025-11-15 20:20:28,110 INFO    MainThread:92567 [wandb_init.py:init():1040] starting run threads in backend
2025-11-15 20:20:28,556 INFO    MainThread:92567 [wandb_run.py:_console_start():2504] atexit reg
2025-11-15 20:20:28,556 INFO    MainThread:92567 [wandb_run.py:_redirect():2352] redirect: wrap_raw
2025-11-15 20:20:28,557 INFO    MainThread:92567 [wandb_run.py:_redirect():2421] Wrapping output streams.
2025-11-15 20:20:28,557 INFO    MainThread:92567 [wandb_run.py:_redirect():2444] Redirects installed.
2025-11-15 20:20:28,562 INFO    MainThread:92567 [wandb_init.py:init():1080] run started, returning control to user process
